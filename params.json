{
  "name": "Searchconsoler",
  "tagline": "R interface with Google Search Console API v3, including Search Analytics.",
  "body": "# searchConsoleR\r\n\r\n[![CRAN](http://www.r-pkg.org/badges/version/searchConsoleR)](http://cran.r-project.org/package=searchConsoleR)\r\n[![Travis-CI Build Status](https://travis-ci.org/MarkEdmondson1234/searchConsoleR.svg?branch=master)](https://travis-ci.org/MarkEdmondson1234/searchConsoleR)\r\n\r\nR interface with Google Search Console (formally Google Webmaster Tools) API v3.\r\n\r\n# News\r\n\r\nCheck out the [news](news.md) for latest updates.\r\n\r\n## Setup Guide\r\n\r\nInstall dependency `googleAuthR` from CRAN:\r\n```r\r\ninstall.packages(\"googleAuthR\")\r\nlibrary(googleAuthR)\r\n```\r\n\r\nInstall `searchConsoleR` 0.2.0 from CRAN:\r\n```r\r\ninstall.packages(\"searchConsoleR\")\r\nlibrary(searchConsoleR)\r\n```\r\n\r\nIf you want the development version of `searchConsoleR` on Github:\r\n\r\n```r\r\ndevtools::install_github(\"MarkEdmondson1234/searchConsoleR\")\r\nlibrary(searchConsoleR)\r\n```\r\n\r\n## Shiny Compatible\r\nAuthentication can be done locally or within a Shiny app. See a very bare bones example here: https://mark.shinyapps.io/searchConsoleRDemo/\r\n\r\n## Info Links\r\n\r\n[Google Search Console](http://www.google.com/webmasters/tools/)\r\n\r\n[Search Console v3 API docs](https://developers.google.com/webmaster-tools/)\r\n\r\n## Function Quick Guide\r\n\r\n### Search analytics\r\n* `search_analytics()` - download Google SEO data into an R dataframe.\r\n\r\n### Website admin\r\n* `list_websites()` - list websites in your Google Search Console.\r\n* `add_website()` - add a website to your Google Search Console.\r\n* `delete_website()` - delete a website from your Google Search Console.\r\n\r\n### Sitemaps\r\n* `list_sitemaps()` - list sitemaps recognised in Google Search Console.\r\n* `add_sitemap()` - add sitemap URL location to Google Search Console.\r\n* `delete_sitemap()` - remove sitemap URL location in Google Search Console.\r\n\r\n### Error listings\r\n* `crawl_errors()` - list various types of crawl errors googlebot has found.\r\n* `list_crawl_error_samples()` - get a list of example URLs with errors.\r\n* `error_sample_url()` - show details about an example URL error (for example, links to a 404 URL)\r\n* `fix_sample_url()` - mark a URL as fixed.\r\n\r\n### Authentication functions from googleAuthR\r\n\r\n* `scr_auth()` - main authentication function. Works locally and within a Shiny environment.\r\n\r\n## Work flow\r\n\r\nWork flow always starts with authenticating with Google:\r\n```r\r\nlibrary(searchConsoleR)\r\nscr_auth()\r\n```\r\n\r\nYour browser window should open up and go through the Google sign in OAuth2 flow. Verify with a user that has Search Console access to the websites you want to work with.\r\n\r\nCheck out the documentation of any function for a guide on what else can be done.\r\n```r\r\n?searchConsoleR\r\n```\r\n\r\nIf you authenticate ok, you should be able to see a list of your websites in the Search Console via:\r\n\r\n```r\r\nsc_websites <- list_websites()\r\nsc_websites\r\n```\r\n\r\nWe'll need one unique ```sc_websites$siteUrl``` for the majority of the other functions.\r\n\r\nMost people will find the Search Analytics most useful.  All methods from the web interface are available.  \r\n\r\nHere is an example query, which downloads the top 100 rows of queries per page for the month of July 2015, for United Kingdom desktop web searches:\r\n\r\n```r\r\ngbr_desktop_queries <- \r\n    search_analytics(\"http://example.com\", \r\n                     \"2015-07-01\", \"2015-07-31\", \r\n                     c(\"query\", \"page\"), \r\n                     dimensionFilterExp = c(\"device==DESKTOP\",\"country==GBR\"), \r\n                     searchType=\"web\", rowLimit = 100)\r\n```\r\n\r\nFor a lot more details see: \r\n```r\r\n?search_analytics\r\n```\r\n\r\n### Batching\r\n\r\nYou can get more than the standard 5000 rows via batching.  There are two methods available, one via a API call per date, the other using the APIs `startRow` parameter.\r\n\r\nThe date method gets more impressions for 0 click rows, the batch method is quicker but gets just rows with clicks. \r\n\r\n```r\r\ntest0 <- search_analytics(\"http://www.example.co.uk\", \r\n                          dimensions = c(\"date\",\"query\",\"page\",\"country\"), \r\n                          rowLimit = 200000, \r\n                          walk_data = \"byBatch\")\r\nBatching data via method: byBatch\r\n\r\n### test0 has 13063 rows\r\n\r\ntest <- search_analytics(\"http://www.example.co.uk\", \r\n                         dimensions = c(\"date\",\"query\",\"page\",\"country\"), \r\n                         walk_data = \"byDate\")\r\nBatching data via method: byDate\r\n\r\n### test has 419957 rows\r\n\r\n> sum(test0$clicks)\r\n[1] 12866\r\n> sum(test$clicks)\r\n[1] 12826\r\n> sum(test$impressions)\r\n[1] 1420217\r\n> sum(test0$impressions)\r\n[1] 441029\r\n> \r\n\r\n```\r\n\r\n## Demo script\r\n\r\nHere is an example for downloading daily data and exporting to .csv\r\n\r\n```r\r\n## A script to download and archive Google search analytics\r\n##\r\n## Demo of searchConsoleR R package.\r\n##\r\n## Version 1 - 10th August 2015\r\n##\r\n## Mark Edmondson (http://markedmondson.me)\r\n\r\nlibrary(searchConsoleR)\r\n\r\n## change this to the website you want to download data for. Include http\r\nwebsite <- \"http://copenhagenish.me\"\r\n\r\n## data is in search console reliably 3 days ago, so we donwnload from then\r\n## today - 3 days\r\nstart <- Sys.Date() - 3\r\n## one days data, but change it as needed\r\nend <- Sys.Date() - 3 \r\n\r\n## what to download, choose between data, query, page, device, country\r\ndownload_dimensions <- c('date','query')\r\n\r\n## what type of Google search, choose between 'web', 'video' or 'image'\r\ntype <- c('web')\r\n\r\n## other options available, check out ?search_analytics in the R console\r\n\r\n## Authorize script with Search Console.  \r\n## First time you will need to login to Google,\r\n## but should auto-refresh after that so can be put in \r\n## Authorize script with an account that has access to website.\r\nscr_auth()\r\n\r\n## first time stop here and wait for authorisation\r\n\r\n## get the search analytics data\r\ndata <- search_analytics(siteURL = website, \r\n                         startDate = start, \r\n                         endDate = end, \r\n                         dimensions = download_dimensions, \r\n                         searchType = type)\r\n\r\n## do stuff to the data\r\n## combine with Google Analytics, filter, apply other stats etc.\r\n\r\n## write a csv to a nice filename\r\nfilename <- paste(\"search_analytics\",\r\n                  Sys.Date(),\r\n                  paste(download_dimensions, collapse = \"\",sep=\"\"),\r\n                  type,\".csv\",sep=\"-\")\r\n\r\nwrite.csv(data, filename)\r\n```\r\n\r\n## The dimensionFilterExp parameter\r\n\r\nThis parameter is used in search_analytics to filter the result.\r\n\r\nFilter using this format: ```filter operator expression```\r\n\r\nFilter can be one of:\r\n\r\n* `country`,\r\n* `device`\r\n* `page`\r\n* `query`\r\n\r\nOperator can be one of ```~~, ==, !~, !=``` where the symbols mean:\r\n\r\n* `~~` : 'contains',\r\n* `==` : 'equals',\r\n* `!~` : 'notContains',\r\n* `!=` : 'notEquals'\r\n\r\nExpression formatting:\r\n\r\n* for ```page``` or ```query``` is free text.\r\n* for ```country``` must be the three letter country code as per the [the ISO 3166-1 alpha-3](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3) standard. e.g. USA, GBR = United Kingdom, DNK = Denmark\r\n* for ```device``` must be one of:  'MOBILE', 'DESKTOP' or 'TABLET'\r\n\r\nYou can have multiple ```AND``` filters by putting them in a character vector.  The below looks for desktop searches in the United Kingdom, not showing the homepage and not including queries containing 'brandterm'.\r\n\r\n```\r\nc(\"device==DESKTOP\",\"country==GBR\", \"page!=/home\", \"query!~brandterm\")\r\n```\r\n\r\n```OR``` filters aren't yet supported in the API.\r\n\r\n## Using your own Google API project \r\n\r\nAs default `searchConsoleR` uses its own Google API project to grant requests, but if you want to use your own keys:\r\n\r\n1. Set up your project in the [Google API Console](https://developers.google.com/identity/sign-in/web/devconsole-project) to use the search console v3 API.\r\n\r\n### For local use\r\n2. Click 'Create a new Client ID', and choose \"Installed Application\".\r\n3. Note your Client ID and secret.\r\n4. Modify these options after `searchConsoleR` has been loaded:\r\n  + `options(\"searchConsoleR.client_id\" = \"YOUR_CLIENT_ID\")`\r\n  + `options(\"searchConsoleR.client_secret\" = \"YOUR_CLIENT_SECRET\")`\r\n\r\n### For Shiny use\r\n2. Click 'Create a new Client ID', and choose \"Web Application\".\r\n3. Note your Client ID and secret.\r\n4. Add the URL of where your Shiny app will run, as well as your local host for testing including a port number.  e.g. https://mark.shinyapps.io/searchConsoleRDemo/ and http://127.0.0.1:4624\r\n5. In your Shiny script modify these options:\r\n  + `options(\"searchConsoleR.webapp.client_id\" = \"YOUR_CLIENT_ID\")`\r\n  + `options(\"searchConsoleR.webapp.client_secret\" = \"YOUR_CLIENT_SECRET\")`\r\n6. Run the app locally specifying the port number you used e.g. `shiny::runApp(port=4624)`\r\n7. Or deploy to your Shiny Server that deploys to web port (80 or 443).\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}